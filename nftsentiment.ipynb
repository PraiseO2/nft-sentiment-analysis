{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFT Authenticity and Prediction using Sentiment Analysis and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import tqdm\n",
    "import tqdm.asyncio\n",
    "import nest_asyncio\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import pandas as pd\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from aiohttp import ClientSession, TCPConnector\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_slugs = ['evolved-apes-inc','oraclenft','boredapeyachtclub','neo-tokyo-identities','cool-cats-nft','cryptopunks','veefriends']\n",
    "slug_date = {}\n",
    "slug_price = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSea Metrics from Collection Slugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetchData(url,session):\n",
    "    async with session.get(url) as response:\n",
    "        try:\n",
    "            response = await response.read()\n",
    "            assert 'detail' not in json.loads(response.decode('UTF-8'))\n",
    "            return response\n",
    "        except:\n",
    "            await asyncio.sleep(5)\n",
    "            return await fetchData(url,session)\n",
    "\n",
    "async def transactionScrape():\n",
    "    tasks = []\n",
    "    responses = []\n",
    "    connector = TCPConnector(limit_per_host=1)\n",
    "    url = \"https://api.opensea.io/api/v1/events?collection_slug={slug}&only_opensea=false&event_type=successful&limit=300&occurred_after={start}&occurred_before={end}\"\n",
    "    headers={\"Accept\": \"application/json\", \"X-API-KEY\": os.getenv('OPENSEA_API_KEY')}\n",
    "    async with ClientSession(connector=connector, headers=headers) as session:\n",
    "        for i in range(len(sample_slugs)):\n",
    "            start_date = datetime.fromisoformat(slug_date[sample_slugs[i]].split('T')[0]) - relativedelta(days=1)\n",
    "            for j in range(14):\n",
    "                start_date = start_date + relativedelta(days=1)\n",
    "                end_date = start_date + relativedelta(days=1) \n",
    "                task = asyncio.ensure_future(fetchData(url.format(slug=sample_slugs[i],start=start_date.timestamp(), end=end_date.timestamp()),session))\n",
    "                tasks.append(task)\n",
    "        for f in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            responses.append(await f)\n",
    "    for response in responses:\n",
    "        response = json.loads(response.decode('utf8'))\n",
    "        try:\n",
    "            collection_slug = response['asset_events'][0]['collection_slug'] \n",
    "            for event in response['asset_events']:\n",
    "                slug_price[collection_slug]['total_volume'] += float(event['total_price'])/1000000000000000000\n",
    "                slug_price[collection_slug]['num_transactions'] += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "async def collectionScrape():\n",
    "    tasks = []\n",
    "    responses = []\n",
    "    connector = TCPConnector()\n",
    "    url = \"https://api.opensea.io/api/v1/collection/{}\"\n",
    "    async with ClientSession(connector=connector) as session:\n",
    "        for i in range(len(sample_slugs)):\n",
    "            task = asyncio.ensure_future(fetchData(url.format(sample_slugs[i]),session))\n",
    "            tasks.append(task)\n",
    "        for f in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            responses.append(await f)\n",
    "    for response in responses:\n",
    "        response = json.loads(response.decode('utf8'))\n",
    "        name = response['collection']['name']\n",
    "        floor = response['collection']['stats']['floor_price']\n",
    "        volume = response['collection']['stats']['total_volume']\n",
    "        date_created = response['collection']['created_date']\n",
    "        slug_date[response['collection']['slug']] = date_created\n",
    "        slug_price[response['collection']['slug']] = {'total_volume' : 0, 'num_transactions': 0 }\n",
    "        print(f'{name}: Floor: {floor}ETH --- Total Volume: {volume}ETH --- Created {date_created}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Collection Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 34.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cool Cats NFT: Floor: 7.95ETH --- Total Volume: 58832.68086868852ETH --- Created 2021-06-27T09:03:35.403074\n",
      "Evolved Apes Inc: Floor: 0.0025ETH --- Total Volume: 1155.893264119258ETH --- Created 2021-09-23T12:30:03.410309\n",
      "Neo Tokyo Identities: Floor: 16.45ETH --- Total Volume: 11202.127364958142ETH --- Created 2021-10-04T15:14:32.376341\n",
      "Bored Ape Yacht Club: Floor: 51.98ETH --- Total Volume: 248435.61510895318ETH --- Created 2021-04-22T23:14:03.967121\n",
      "VeeFriends: Floor: 7.948ETH --- Total Volume: 32010.294588127756ETH --- Created 2021-05-11T18:22:19.398578\n",
      "CryptoPunks: Floor: NoneETH --- Total Volume: 733080.3212493034ETH --- Created 2019-04-26T22:13:09.691572\n",
      "Oracle (official): Floor: 0.0ETH --- Total Volume: 27.59211999999997ETH --- Created 2021-09-22T10:53:26.948567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.ensure_future(collectionScrape())\n",
    "loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Transaction Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [05:17<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boredapeyachtclub': {'num_transactions': 1493,\n",
      "                       'total_volume': 1036.042150458877},\n",
      " 'cool-cats-nft': {'num_transactions': 3000, 'total_volume': 1348.559469115312},\n",
      " 'cryptopunks': {'num_transactions': 112, 'total_volume': 50.751900000000006},\n",
      " 'evolved-apes-inc': {'num_transactions': 2968,\n",
      "                      'total_volume': 359.1697327089688},\n",
      " 'neo-tokyo-identities': {'num_transactions': 541,\n",
      "                          'total_volume': 5044.5502018807865},\n",
      " 'oraclenft': {'num_transactions': 465, 'total_volume': 20.559649999999987},\n",
      " 'veefriends': {'num_transactions': 86, 'total_volume': 204.1384013352507}}\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.ensure_future(transactionScrape())\n",
    "loop.run_until_complete(future)\n",
    "pprint(slug_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cool-cats-nft': {'num_transactions': 900, 'total_volume': 60.342537256013955},\n",
      " 'cryptopunks': {'num_transactions': 3, 'total_volume': 2.7},\n",
      " 'evolved-apes-inc': {'num_transactions': 2028,\n",
      "                      'total_volume': 320.1946983101896},\n",
      " 'neo-tokyo-identities': {'num_transactions': 463,\n",
      "                          'total_volume': 4264.695525091693},\n",
      " 'veefriends': {'num_transactions': 10, 'total_volume': 14.500000000024919}}\n"
     ]
    }
   ],
   "source": [
    "pprint(slug_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Historical Tweet Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(features, labels):\n",
    "    scores = cross_val_score(GaussianNB(), features, labels, scoring='accuracy', cv=10)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSVM(train_x, test_x, train_y, test_y):\n",
    "    model = svm.SVC()\n",
    "    model.fit(train_x,train_y)\n",
    "    y_pred = model.predict(test_x)\n",
    "    return metrics.accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictMLP(train_x, test_x, train_y, test_y):\n",
    "    n_features = train_x.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_x, train_y, epochs=150, batch_size=32, verbose=0)\n",
    "    pyplot.title('Learning Curve')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Binary Cross Entropy')\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()   \n",
    "    loss, acc = model.evaluate(test_x, test_y, verbose=0)\n",
    "    return acc\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
