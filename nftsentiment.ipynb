{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFT Authenticity and Prediction using Sentiment Analysis and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import tqdm\n",
    "import tqdm.asyncio\n",
    "import nest_asyncio\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import pandas as pd\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from aiohttp import ClientSession, TCPConnector\n",
    "from matplotlib import pyplot\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_slugs = ['evolved-apes-inc','oraclenft','boredapeyachtclub','neo-tokyo-identities','cool-cats-nft','cryptopunks','veefriends']\n",
    "slug_date = {}\n",
    "slug_price = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSea Metrics from Collection Slugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetchData(url,session):\n",
    "    async with session.get(url) as response:\n",
    "        try:\n",
    "            response = await response.read()\n",
    "            assert 'detail' not in json.loads(response.decode('UTF-8'))\n",
    "            return response\n",
    "        except:\n",
    "            await asyncio.sleep(5)\n",
    "            return await fetchData(url,session)\n",
    "\n",
    "async def transactionScrape():\n",
    "    tasks = []\n",
    "    responses = []\n",
    "    connector = TCPConnector(limit_per_host=1)\n",
    "    url = \"https://api.opensea.io/api/v1/events?collection_slug={slug}&only_opensea=false&event_type=successful&limit=300&occurred_after={start}&occurred_before={end}\"\n",
    "    headers={\"Accept\": \"application/json\", \"X-API-KEY\": os.getenv('OPENSEA_API_KEY')}\n",
    "    async with ClientSession(connector=connector, headers=headers) as session:\n",
    "        for i in range(len(sample_slugs)):\n",
    "            start_date = datetime.fromisoformat(slug_date[sample_slugs[i]].split('T')[0]) - relativedelta(days=1)\n",
    "            for j in range(14):\n",
    "                start_date = start_date + relativedelta(days=1)\n",
    "                end_date = start_date + relativedelta(days=1) \n",
    "                task = asyncio.ensure_future(fetchData(url.format(slug=sample_slugs[i],start=start_date.timestamp(), end=end_date.timestamp()),session))\n",
    "                tasks.append(task)\n",
    "        for f in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            responses.append(await f)\n",
    "    for response in responses:\n",
    "        response = json.loads(response.decode('utf8'))\n",
    "        try:\n",
    "            collection_slug = response['asset_events'][0]['collection_slug'] \n",
    "            for event in response['asset_events']:\n",
    "                slug_price[collection_slug]['total_volume'] += float(event['total_price'])/1000000000000000000\n",
    "                slug_price[collection_slug]['num_transactions'] += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "async def collectionScrape():\n",
    "    tasks = []\n",
    "    responses = []\n",
    "    connector = TCPConnector()\n",
    "    url = \"https://api.opensea.io/api/v1/collection/{}\"\n",
    "    async with ClientSession(connector=connector) as session:\n",
    "        for i in range(len(sample_slugs)):\n",
    "            task = asyncio.ensure_future(fetchData(url.format(sample_slugs[i]),session))\n",
    "            tasks.append(task)\n",
    "        for f in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            responses.append(await f)\n",
    "    for response in responses:\n",
    "        response = json.loads(response.decode('utf8'))\n",
    "        name = response['collection']['name']\n",
    "        floor = response['collection']['stats']['floor_price']\n",
    "        volume = response['collection']['stats']['total_volume']\n",
    "        date_created = response['collection']['created_date']\n",
    "        slug_date[response['collection']['slug']] = date_created\n",
    "        slug_price[response['collection']['slug']] = {'total_volume' : 0, 'num_transactions': 0 }\n",
    "        print(f'{name}: Floor: {floor}ETH --- Total Volume: {volume}ETH --- Created {date_created}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Collection Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 34.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cool Cats NFT: Floor: 7.95ETH --- Total Volume: 58832.68086868852ETH --- Created 2021-06-27T09:03:35.403074\n",
      "Evolved Apes Inc: Floor: 0.0025ETH --- Total Volume: 1155.893264119258ETH --- Created 2021-09-23T12:30:03.410309\n",
      "Neo Tokyo Identities: Floor: 16.45ETH --- Total Volume: 11202.127364958142ETH --- Created 2021-10-04T15:14:32.376341\n",
      "Bored Ape Yacht Club: Floor: 51.98ETH --- Total Volume: 248435.61510895318ETH --- Created 2021-04-22T23:14:03.967121\n",
      "VeeFriends: Floor: 7.948ETH --- Total Volume: 32010.294588127756ETH --- Created 2021-05-11T18:22:19.398578\n",
      "CryptoPunks: Floor: NoneETH --- Total Volume: 733080.3212493034ETH --- Created 2019-04-26T22:13:09.691572\n",
      "Oracle (official): Floor: 0.0ETH --- Total Volume: 27.59211999999997ETH --- Created 2021-09-22T10:53:26.948567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.ensure_future(collectionScrape())\n",
    "loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Transaction Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [05:17<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boredapeyachtclub': {'num_transactions': 1493,\n",
      "                       'total_volume': 1036.042150458877},\n",
      " 'cool-cats-nft': {'num_transactions': 3000, 'total_volume': 1348.559469115312},\n",
      " 'cryptopunks': {'num_transactions': 112, 'total_volume': 50.751900000000006},\n",
      " 'evolved-apes-inc': {'num_transactions': 2968,\n",
      "                      'total_volume': 359.1697327089688},\n",
      " 'neo-tokyo-identities': {'num_transactions': 541,\n",
      "                          'total_volume': 5044.5502018807865},\n",
      " 'oraclenft': {'num_transactions': 465, 'total_volume': 20.559649999999987},\n",
      " 'veefriends': {'num_transactions': 86, 'total_volume': 204.1384013352507}}\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.ensure_future(transactionScrape())\n",
    "loop.run_until_complete(future)\n",
    "pprint(slug_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cool-cats-nft': {'num_transactions': 900, 'total_volume': 60.342537256013955},\n",
      " 'cryptopunks': {'num_transactions': 3, 'total_volume': 2.7},\n",
      " 'evolved-apes-inc': {'num_transactions': 2028,\n",
      "                      'total_volume': 320.1946983101896},\n",
      " 'neo-tokyo-identities': {'num_transactions': 463,\n",
      "                          'total_volume': 4264.695525091693},\n",
      " 'veefriends': {'num_transactions': 10, 'total_volume': 14.500000000024919}}\n"
     ]
    }
   ],
   "source": [
    "pprint(slug_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Historical Tweet Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = os.getenv('CONSUMER_KEY')\n",
    "consumer_secret = os.getenv('CONSUMER_SECRET')\n",
    "access_token = os.getenv('ACCESS_TOKEN')\n",
    "access_token_secret = os.getenv('ACCESS_TOKEN_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Bored Ape Yacht Club\n",
      "1           Evolved Apes NFT\n",
      "2                 Oracle NFT\n",
      "3       Neo Tokyo Identities\n",
      "4              Cool Cats NFT\n",
      "5             Hype Hippo NFT\n",
      "6             Veefriends NFT\n",
      "7            The Sandbox NFT\n",
      "8                 Apymon NFT\n",
      "9             CyberKongz NFT\n",
      "10               Meebits NFT\n",
      "11        World of Women NFT\n",
      "12     Mutant Human Club NFT\n",
      "13        The Doge Pound NFT\n",
      "14        Creature World NFT\n",
      "15         Angry Anglers NFT\n",
      "16                CloneX NFT\n",
      "17               Doodles NFT\n",
      "18      Panda Golf Squad NFT\n",
      "19        Pepsi Mic Drop NFT\n",
      "20         Miss Universe NFT\n",
      "21    CryptoBull Society NFT\n",
      "22      Chromie Squiggle NFT\n",
      "23    Farmer Apes (FAYC) NFT\n",
      "24          Jadu Jetpack NFT\n",
      "25            Lazy Lions NFT\n",
      "26          CryptoVoxels NFT\n",
      "27           Doge Battle NFT\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "collections = pd.read_csv(\"collections.csv\")[\"name\"]\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(proj):\n",
    "    filename = \"./data/\" + \"_\".join(proj.split(\" \")) + \".csv\"\n",
    "    print(\"Collecting tweets for:\", proj)\n",
    "    print(\"Writing results to\", filename)\n",
    "\n",
    "    resp = api.search_full_archive(\"prod\", proj)\n",
    "\n",
    "    tweets = []\n",
    "    timestamps = []\n",
    "\n",
    "    for status in resp:\n",
    "        tweets.append(status.text)\n",
    "        timestamps.append(status.created_at)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "            \"tweets\": pd.Series(tweets),\n",
    "            \"timestamps\": pd.Series(timestamps)\n",
    "            })\n",
    "\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweets for: Bored Ape Yacht Club\n",
      "Writing results to ./data/Bored_Ape_Yacht_Club.csv\n",
      "Collecting tweets for: Evolved Apes NFT\n",
      "Writing results to ./data/Evolved_Apes_NFT.csv\n",
      "Collecting tweets for: Oracle NFT\n",
      "Writing results to ./data/Oracle_NFT.csv\n",
      "Collecting tweets for: Neo Tokyo Identities\n",
      "Writing results to ./data/Neo_Tokyo_Identities.csv\n",
      "Collecting tweets for: Cool Cats NFT\n",
      "Writing results to ./data/Cool_Cats_NFT.csv\n",
      "Collecting tweets for: Hype Hippo NFT\n",
      "Writing results to ./data/Hype_Hippo_NFT.csv\n",
      "Collecting tweets for: Veefriends NFT\n",
      "Writing results to ./data/Veefriends_NFT.csv\n",
      "Collecting tweets for: The Sandbox NFT\n",
      "Writing results to ./data/The_Sandbox_NFT.csv\n",
      "Collecting tweets for: Apymon NFT\n",
      "Writing results to ./data/Apymon_NFT.csv\n",
      "Collecting tweets for: CyberKongz NFT\n",
      "Writing results to ./data/CyberKongz_NFT.csv\n",
      "Collecting tweets for: Meebits NFT\n",
      "Writing results to ./data/Meebits_NFT.csv\n",
      "Collecting tweets for: World of Women NFT\n",
      "Writing results to ./data/World_of_Women_NFT.csv\n",
      "Collecting tweets for: Mutant Human Club NFT\n",
      "Writing results to ./data/Mutant_Human_Club_NFT.csv\n",
      "Collecting tweets for: The Doge Pound NFT\n",
      "Writing results to ./data/The_Doge_Pound_NFT.csv\n",
      "Collecting tweets for: Creature World NFT\n",
      "Writing results to ./data/Creature_World_NFT.csv\n",
      "Collecting tweets for: Angry Anglers NFT\n",
      "Writing results to ./data/Angry_Anglers_NFT.csv\n",
      "Collecting tweets for: CloneX NFT\n",
      "Writing results to ./data/CloneX_NFT.csv\n",
      "Collecting tweets for: Doodles NFT\n",
      "Writing results to ./data/Doodles_NFT.csv\n",
      "Collecting tweets for: Panda Golf Squad NFT\n",
      "Writing results to ./data/Panda_Golf_Squad_NFT.csv\n",
      "Collecting tweets for: Pepsi Mic Drop NFT\n",
      "Writing results to ./data/Pepsi_Mic_Drop_NFT.csv\n",
      "Collecting tweets for: Miss Universe NFT\n",
      "Writing results to ./data/Miss_Universe_NFT.csv\n",
      "Collecting tweets for: CryptoBull Society NFT\n",
      "Writing results to ./data/CryptoBull_Society_NFT.csv\n",
      "Collecting tweets for: Chromie Squiggle NFT\n",
      "Writing results to ./data/Chromie_Squiggle_NFT.csv\n",
      "Collecting tweets for: Farmer Apes (FAYC) NFT\n",
      "Writing results to ./data/Farmer_Apes_(FAYC)_NFT.csv\n",
      "Collecting tweets for: Jadu Jetpack NFT\n",
      "Writing results to ./data/Jadu_Jetpack_NFT.csv\n",
      "Collecting tweets for: Lazy Lions NFT\n",
      "Writing results to ./data/Lazy_Lions_NFT.csv\n",
      "Collecting tweets for: CryptoVoxels NFT\n",
      "Writing results to ./data/CryptoVoxels_NFT.csv\n",
      "Collecting tweets for: Doge Battle NFT\n",
      "Writing results to ./data/Doge_Battle_NFT.csv\n"
     ]
    }
   ],
   "source": [
    "for proj in collections:\n",
    "    get_tweets(proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(features, labels):\n",
    "    scores = cross_val_score(GaussianNB(), features, labels, scoring='accuracy', cv=10)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSVM(train_x, test_x, train_y, test_y):\n",
    "    model = svm.SVC()\n",
    "    model.fit(train_x,train_y)\n",
    "    y_pred = model.predict(test_x)\n",
    "    return metrics.accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictMLP(train_x, test_x, train_y, test_y):\n",
    "    n_features = train_x.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_x, train_y, epochs=150, batch_size=32, verbose=0)\n",
    "    pyplot.title('Learning Curve')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Binary Cross Entropy')\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()   \n",
    "    loss, acc = model.evaluate(test_x, test_y, verbose=0)\n",
    "    return acc\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
